{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f10e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import joblib\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d54c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stesml.model_tools import train_and_validate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49f5d7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):   \n",
    "    # Save the study before running the next trial\n",
    "    joblib.dump(study, \"../studies/study_\" + model_type + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H\") + \".pkl\")\n",
    "    \n",
    "    if model_type == 'NN':\n",
    "        scale = True\n",
    "        n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "        n_hidden_units = trial.suggest_int(\"n_hidden_units\", 10, 100)\n",
    "        batch_size = trial.suggest_int(\"batch_size\", 1, 100, log=True)\n",
    "        parameters = {'n_layers': n_layers, 'n_hidden_units': n_hidden_units, 'batch_size': batch_size, 'epochs': 200}\n",
    "        result, addendum = train_and_validate_model(data_dir, model_type, target, metric, scale, parameters, n_repeats, t_max=360, split_test_data=split_test_data)\n",
    "    elif model_type == 'XGBoost':\n",
    "        scale = False\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 1)\n",
    "        num_boost_round = 10000 # Set this as a maximum, model will stop with early stopping\n",
    "        parameters = {'learning_rate': learning_rate, 'num_boost_round': num_boost_round}\n",
    "        result, addendum = train_and_validate_model(data_dir, model_type, target, metric, scale, parameters, n_repeats, split_test_data=split_test_data)\n",
    "    elif model_type == 'RandomForest':\n",
    "        scale = False\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 1, 200, log=True)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 1, 100)\n",
    "        max_samples = trial.suggest_float(\"max_samples\", .01, 1, log=True)\n",
    "        parameters = {'n_estimators': n_estimators, 'max_depth': max_depth, 'max_samples': max_samples}\n",
    "        result, addendum = train_and_validate_model(data_dir, model_type, target, metric, scale, parameters, n_repeats, split_test_data=split_test_data)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8003a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/Sulfur_Models/heating/heating_all\"\n",
    "model_type = 'XGBoost' # Options: NN, XGBoost, RandomForest\n",
    "target = 'h' # Options: Tavg, h\n",
    "metric = 'rmse' # Options: rmse, r2\n",
    "n_repeats = 1 # Number of times to repeat 5-fold CV. Each repeat gives a different shuffle.\n",
    "split_test_data = True # Split data into train (64%), val (16%), and test (20%) (True) or just train (80%) and val (20%) (False)\n",
    "\n",
    "if metric == 'rmse':\n",
    "    direction = 'minimize'\n",
    "elif metric == 'r2':\n",
    "    directon = 'maximize'\n",
    "\n",
    "load_study = False\n",
    "study_name = \"study_XGBoost_20220714-09.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34ff5265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 12:11:48,992]\u001b[0m A new study created in memory with name: no-name-31c265be-d0a1-4334-ac1b-b17b654e83f7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if load_study:\n",
    "    study = joblib.load(\"../studies/\" + study_name)\n",
    "    print(\"Best trial until now:\")\n",
    "    print(\" Value: \", study.best_trial.value)\n",
    "    print(\" Params: \")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "else:\n",
    "    study = optuna.create_study(direction=direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daa16b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:97.86226\n",
      "[20]\ttest-rmse:24.31489\n",
      "[40]\ttest-rmse:8.76030\n",
      "[60]\ttest-rmse:6.67400\n",
      "[80]\ttest-rmse:6.45699\n",
      "[100]\ttest-rmse:6.39986\n",
      "[120]\ttest-rmse:6.36710\n",
      "[140]\ttest-rmse:6.28952\n",
      "[160]\ttest-rmse:6.25675\n",
      "[180]\ttest-rmse:6.21325\n",
      "[200]\ttest-rmse:6.20491\n",
      "[220]\ttest-rmse:6.20457\n",
      "[228]\ttest-rmse:6.20474\n",
      "Split #0, This Result: 6.2047, Average Result: 6.2047\n",
      "[12:15:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:86.87063\n",
      "[20]\ttest-rmse:22.29157\n",
      "[40]\ttest-rmse:9.17615\n",
      "[60]\ttest-rmse:6.97494\n",
      "[80]\ttest-rmse:6.48093\n",
      "[100]\ttest-rmse:6.32092\n",
      "[120]\ttest-rmse:6.26121\n",
      "[140]\ttest-rmse:6.18977\n",
      "[160]\ttest-rmse:6.16905\n",
      "[180]\ttest-rmse:6.15912\n",
      "[200]\ttest-rmse:6.14851\n",
      "[220]\ttest-rmse:6.13595\n",
      "[240]\ttest-rmse:6.12984\n",
      "[260]\ttest-rmse:6.13060\n",
      "[263]\ttest-rmse:6.13171\n",
      "Split #1, This Result: 6.1302, Average Result: 6.1675\n",
      "[12:18:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:84.60303\n",
      "[20]\ttest-rmse:21.02771\n",
      "[40]\ttest-rmse:6.49171\n",
      "[60]\ttest-rmse:3.49484\n",
      "[80]\ttest-rmse:2.96887\n",
      "[100]\ttest-rmse:2.75831\n",
      "[120]\ttest-rmse:2.64304\n",
      "[140]\ttest-rmse:2.59728\n",
      "[160]\ttest-rmse:2.57739\n",
      "[180]\ttest-rmse:2.54589\n",
      "[200]\ttest-rmse:2.53006\n",
      "[220]\ttest-rmse:2.52388\n",
      "[240]\ttest-rmse:2.51177\n",
      "[260]\ttest-rmse:2.50498\n",
      "[280]\ttest-rmse:2.50243\n",
      "[300]\ttest-rmse:2.49569\n",
      "[320]\ttest-rmse:2.49478\n",
      "[340]\ttest-rmse:2.49276\n",
      "[360]\ttest-rmse:2.49217\n",
      "[380]\ttest-rmse:2.49015\n",
      "[400]\ttest-rmse:2.48809\n",
      "[420]\ttest-rmse:2.48867\n",
      "[427]\ttest-rmse:2.48930\n",
      "Split #2, This Result: 2.4893, Average Result: 4.9414\n",
      "[12:24:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:96.19128\n",
      "[20]\ttest-rmse:22.89692\n",
      "[40]\ttest-rmse:6.45124\n",
      "[60]\ttest-rmse:4.09806\n",
      "[80]\ttest-rmse:4.03381\n",
      "[88]\ttest-rmse:4.03267\n",
      "Split #3, This Result: 4.0326, Average Result: 4.7142\n",
      "[12:25:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:72.32209\n",
      "[20]\ttest-rmse:16.73697\n",
      "[40]\ttest-rmse:4.94263\n",
      "[60]\ttest-rmse:3.07594\n",
      "[80]\ttest-rmse:2.84490\n",
      "[100]\ttest-rmse:2.85719\n",
      "[114]\ttest-rmse:2.90834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 12:26:45,780]\u001b[0m Trial 0 finished with value: 4.353045531223534 and parameters: {'learning_rate': 0.07124237992671427}. Best is trial 0 with value: 4.353045531223534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split #4, This Result: 2.9083, Average Result: 4.3530\n",
      "[12:26:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:74.54008\n",
      "[20]\ttest-rmse:6.84860\n",
      "[40]\ttest-rmse:6.62746\n",
      "[60]\ttest-rmse:6.57717\n",
      "[80]\ttest-rmse:6.51551\n",
      "[100]\ttest-rmse:6.51009\n",
      "[120]\ttest-rmse:6.50727\n",
      "[140]\ttest-rmse:6.49613\n",
      "[160]\ttest-rmse:6.49007\n",
      "[180]\ttest-rmse:6.47706\n",
      "[200]\ttest-rmse:6.47467\n",
      "[220]\ttest-rmse:6.47382\n",
      "[240]\ttest-rmse:6.46819\n",
      "[255]\ttest-rmse:6.46948\n",
      "Split #0, This Result: 6.4696, Average Result: 6.4696\n",
      "[12:30:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:66.23428\n",
      "[20]\ttest-rmse:6.89831\n",
      "[40]\ttest-rmse:6.63302\n",
      "[60]\ttest-rmse:6.57930\n",
      "[80]\ttest-rmse:6.55408\n",
      "[100]\ttest-rmse:6.54286\n",
      "[120]\ttest-rmse:6.53872\n",
      "[127]\ttest-rmse:6.53955\n",
      "Split #1, This Result: 6.5395, Average Result: 6.5046\n",
      "[12:32:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:64.53741\n",
      "[20]\ttest-rmse:2.93453\n",
      "[40]\ttest-rmse:2.65299\n",
      "[60]\ttest-rmse:2.54664\n",
      "[80]\ttest-rmse:2.49621\n",
      "[100]\ttest-rmse:2.47358\n",
      "[120]\ttest-rmse:2.45376\n",
      "[140]\ttest-rmse:2.43948\n",
      "[160]\ttest-rmse:2.42862\n",
      "[180]\ttest-rmse:2.42682\n",
      "[200]\ttest-rmse:2.42010\n",
      "[220]\ttest-rmse:2.41662\n",
      "[240]\ttest-rmse:2.41433\n",
      "[260]\ttest-rmse:2.41143\n",
      "[280]\ttest-rmse:2.40830\n",
      "[300]\ttest-rmse:2.40470\n",
      "[320]\ttest-rmse:2.40324\n",
      "[340]\ttest-rmse:2.40260\n",
      "[360]\ttest-rmse:2.40357\n",
      "[362]\ttest-rmse:2.40340\n",
      "Split #2, This Result: 2.4033, Average Result: 5.1375\n",
      "[12:36:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:73.00532\n",
      "[20]\ttest-rmse:4.22506\n",
      "[40]\ttest-rmse:3.89817\n",
      "[60]\ttest-rmse:3.84051\n",
      "[80]\ttest-rmse:3.81650\n",
      "[100]\ttest-rmse:3.78008\n",
      "[120]\ttest-rmse:3.76373\n",
      "[140]\ttest-rmse:3.74556\n",
      "[160]\ttest-rmse:3.73039\n",
      "[180]\ttest-rmse:3.72827\n",
      "[200]\ttest-rmse:3.72621\n",
      "[220]\ttest-rmse:3.72317\n",
      "[240]\ttest-rmse:3.71644\n",
      "[260]\ttest-rmse:3.71672\n",
      "[280]\ttest-rmse:3.71177\n",
      "[300]\ttest-rmse:3.70814\n",
      "[320]\ttest-rmse:3.70689\n",
      "[340]\ttest-rmse:3.70542\n",
      "[360]\ttest-rmse:3.68324\n",
      "[380]\ttest-rmse:3.68283\n",
      "[400]\ttest-rmse:3.68379\n",
      "[406]\ttest-rmse:3.68361\n",
      "Split #3, This Result: 3.6835, Average Result: 4.7740\n",
      "[12:42:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:54.66365\n",
      "[20]\ttest-rmse:2.74484\n",
      "[40]\ttest-rmse:2.75175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 12:42:45,308]\u001b[0m Trial 1 finished with value: 4.369823234555178 and parameters: {'learning_rate': 0.2982187595588735}. Best is trial 0 with value: 4.353045531223534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split #4, This Result: 2.7532, Average Result: 4.3698\n",
      "[12:42:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:39.87043\n",
      "[20]\ttest-rmse:6.86044\n",
      "[40]\ttest-rmse:6.63881\n",
      "[60]\ttest-rmse:6.55759\n",
      "[80]\ttest-rmse:6.54751\n",
      "[100]\ttest-rmse:6.53834\n",
      "[120]\ttest-rmse:6.53755\n",
      "[140]\ttest-rmse:6.52918\n",
      "[160]\ttest-rmse:6.52601\n",
      "[180]\ttest-rmse:6.52194\n",
      "[200]\ttest-rmse:6.52384\n",
      "[203]\ttest-rmse:6.52381\n",
      "Split #0, This Result: 6.5238, Average Result: 6.5238\n",
      "[12:45:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:35.51924\n",
      "[20]\ttest-rmse:6.75578\n",
      "[40]\ttest-rmse:6.65885\n",
      "[60]\ttest-rmse:6.62677\n",
      "[80]\ttest-rmse:6.60341\n",
      "[100]\ttest-rmse:6.59060\n",
      "[120]\ttest-rmse:6.58960\n",
      "[140]\ttest-rmse:6.59177\n",
      "[147]\ttest-rmse:6.59111\n",
      "Split #1, This Result: 6.5911, Average Result: 6.5575\n",
      "[12:47:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:34.57927\n",
      "[20]\ttest-rmse:3.34133\n",
      "[40]\ttest-rmse:3.11523\n",
      "[60]\ttest-rmse:3.04517\n",
      "[80]\ttest-rmse:3.02562\n",
      "[100]\ttest-rmse:3.01565\n",
      "[120]\ttest-rmse:2.99869\n",
      "[140]\ttest-rmse:2.99467\n",
      "[160]\ttest-rmse:2.99207\n",
      "[180]\ttest-rmse:2.99946\n",
      "Split #2, This Result: 2.9995, Average Result: 5.3715\n",
      "[12:50:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:38.35049\n",
      "[20]\ttest-rmse:4.06013\n",
      "[40]\ttest-rmse:3.82193\n",
      "[60]\ttest-rmse:3.69650\n",
      "[80]\ttest-rmse:3.64449\n",
      "[100]\ttest-rmse:3.62711\n",
      "[120]\ttest-rmse:3.59627\n",
      "[140]\ttest-rmse:3.56764\n",
      "[160]\ttest-rmse:3.56219\n",
      "[170]\ttest-rmse:3.56238\n",
      "Split #3, This Result: 3.5620, Average Result: 4.9191\n",
      "[12:52:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:28.28414\n",
      "[20]\ttest-rmse:3.06660\n",
      "[40]\ttest-rmse:3.07072\n",
      "[51]\ttest-rmse:3.04046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 12:53:16,543]\u001b[0m Trial 2 finished with value: 4.543381194448861 and parameters: {'learning_rate': 0.6420568038686019}. Best is trial 0 with value: 4.353045531223534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split #4, This Result: 3.0405, Average Result: 4.5434\n",
      "[12:53:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:29.76937\n",
      "[20]\ttest-rmse:8.49889\n",
      "[40]\ttest-rmse:8.37600\n",
      "[60]\ttest-rmse:8.35666\n",
      "[71]\ttest-rmse:8.35783\n",
      "Split #0, This Result: 8.3578, Average Result: 8.3578\n",
      "[12:54:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:26.53769\n",
      "[20]\ttest-rmse:6.88829\n",
      "[40]\ttest-rmse:6.82507\n",
      "[60]\ttest-rmse:6.78068\n",
      "[75]\ttest-rmse:6.78181\n",
      "Split #1, This Result: 6.7819, Average Result: 7.5698\n",
      "[12:55:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:25.74581\n",
      "[20]\ttest-rmse:3.24078\n",
      "[40]\ttest-rmse:3.10515\n",
      "[60]\ttest-rmse:3.05052\n",
      "[80]\ttest-rmse:3.03832\n",
      "[90]\ttest-rmse:3.03968\n",
      "Split #2, This Result: 3.0397, Average Result: 6.0598\n",
      "[12:57:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:28.11850\n",
      "[20]\ttest-rmse:3.90457\n",
      "[40]\ttest-rmse:3.67969\n",
      "[60]\ttest-rmse:3.64999\n",
      "[80]\ttest-rmse:3.65023\n",
      "[93]\ttest-rmse:3.64003\n",
      "Split #3, This Result: 3.6379, Average Result: 5.4543\n",
      "[12:58:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:20.51107\n",
      "[20]\ttest-rmse:4.45659\n",
      "[22]\ttest-rmse:4.44309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 12:58:53,253]\u001b[0m Trial 3 finished with value: 5.252532586571922 and parameters: {'learning_rate': 0.7474561798309677}. Best is trial 0 with value: 4.353045531223534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split #4, This Result: 4.4454, Average Result: 5.2525\n",
      "[12:59:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:20.69204\n",
      "[20]\ttest-rmse:7.59031\n",
      "[40]\ttest-rmse:7.57916\n",
      "[50]\ttest-rmse:7.60095\n",
      "Split #0, This Result: 7.6010, Average Result: 7.6010\n",
      "[12:59:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:18.40678\n",
      "[20]\ttest-rmse:6.47404\n",
      "[40]\ttest-rmse:6.17919\n",
      "[58]\ttest-rmse:6.16704\n",
      "Split #1, This Result: 6.1671, Average Result: 6.8840\n",
      "[13:00:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:17.62988\n",
      "[20]\ttest-rmse:3.65756\n",
      "[40]\ttest-rmse:3.49778\n",
      "[60]\ttest-rmse:3.45901\n",
      "[80]\ttest-rmse:3.44347\n",
      "[97]\ttest-rmse:3.44304\n",
      "Split #2, This Result: 3.4419, Average Result: 5.7366\n",
      "[13:02:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:18.74245\n",
      "[20]\ttest-rmse:4.37185\n",
      "[40]\ttest-rmse:4.29978\n",
      "[57]\ttest-rmse:4.28618\n",
      "Split #3, This Result: 4.2863, Average Result: 5.3741\n",
      "[13:03:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:13.44124\n",
      "[20]\ttest-rmse:4.16075\n",
      "[22]\ttest-rmse:4.15728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 13:03:25,674]\u001b[0m Trial 4 finished with value: 5.129486368582173 and parameters: {'learning_rate': 0.8513608907372331}. Best is trial 0 with value: 4.353045531223534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split #4, This Result: 4.1512, Average Result: 5.1295\n",
      "[13:03:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:81.43060\n",
      "[20]\ttest-rmse:6.94803\n",
      "[40]\ttest-rmse:6.68151\n",
      "[60]\ttest-rmse:6.64358\n",
      "[80]\ttest-rmse:6.54389\n",
      "[100]\ttest-rmse:6.52789\n",
      "[120]\ttest-rmse:6.52328\n",
      "[140]\ttest-rmse:6.51373\n",
      "[160]\ttest-rmse:6.50961\n",
      "[180]\ttest-rmse:6.50299\n",
      "[200]\ttest-rmse:6.48949\n",
      "[220]\ttest-rmse:6.49055\n",
      "[224]\ttest-rmse:6.49046\n",
      "Split #0, This Result: 6.4905, Average Result: 6.4905\n",
      "[13:06:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:72.33225\n",
      "[20]\ttest-rmse:6.98172\n",
      "[40]\ttest-rmse:6.50912\n",
      "[60]\ttest-rmse:6.48901\n",
      "[75]\ttest-rmse:6.51060\n",
      "Split #1, This Result: 6.5106, Average Result: 6.5005\n",
      "[13:07:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:70.46687\n",
      "[20]\ttest-rmse:3.16945\n",
      "[40]\ttest-rmse:2.76260\n",
      "[60]\ttest-rmse:2.65847\n",
      "[80]\ttest-rmse:2.61884\n",
      "[100]\ttest-rmse:2.60156\n",
      "[120]\ttest-rmse:2.57991\n",
      "[140]\ttest-rmse:2.57174\n",
      "[160]\ttest-rmse:2.56452\n",
      "[180]\ttest-rmse:2.56382\n",
      "[200]\ttest-rmse:2.56068\n",
      "[220]\ttest-rmse:2.55302\n",
      "[240]\ttest-rmse:2.55288\n",
      "[251]\ttest-rmse:2.55322\n",
      "Split #2, This Result: 2.5532, Average Result: 5.1848\n",
      "[13:11:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:79.86855\n",
      "[20]\ttest-rmse:4.29423\n",
      "[40]\ttest-rmse:4.13448\n",
      "[60]\ttest-rmse:4.06926\n",
      "[80]\ttest-rmse:4.01560\n",
      "[100]\ttest-rmse:3.96102\n",
      "[117]\ttest-rmse:3.95551\n",
      "Split #3, This Result: 3.9551, Average Result: 4.8774\n",
      "[13:12:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:59.88470\n",
      "[20]\ttest-rmse:2.65851\n",
      "[40]\ttest-rmse:2.77315\n",
      "[43]\ttest-rmse:2.75772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 13:13:30,233]\u001b[0m Trial 5 finished with value: 4.457140238683293 and parameters: {'learning_rate': 0.2309862836163988}. Best is trial 0 with value: 4.353045531223534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split #4, This Result: 2.7763, Average Result: 4.4571\n",
      "[13:13:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:58.45140\n",
      "[20]\ttest-rmse:7.23946\n",
      "[40]\ttest-rmse:7.11262\n",
      "[60]\ttest-rmse:7.05165\n",
      "[80]\ttest-rmse:6.99667\n",
      "[100]\ttest-rmse:6.98475\n",
      "[120]\ttest-rmse:6.96939\n",
      "[140]\ttest-rmse:6.96894\n",
      "[160]\ttest-rmse:6.95388\n",
      "[180]\ttest-rmse:6.94983\n",
      "[200]\ttest-rmse:6.94799\n",
      "[220]\ttest-rmse:6.94515\n",
      "[233]\ttest-rmse:6.95619\n",
      "Split #0, This Result: 6.9564, Average Result: 6.9564\n",
      "[13:17:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:51.99060\n",
      "[20]\ttest-rmse:6.13585\n",
      "[40]\ttest-rmse:5.96398\n",
      "[60]\ttest-rmse:5.94733\n",
      "[80]\ttest-rmse:5.91244\n",
      "[100]\ttest-rmse:5.89018\n",
      "[120]\ttest-rmse:5.88469\n",
      "[140]\ttest-rmse:5.88238\n",
      "[153]\ttest-rmse:5.88102\n",
      "Split #1, This Result: 5.8813, Average Result: 6.4188\n",
      "[13:19:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:50.66785\n",
      "[20]\ttest-rmse:2.98608\n",
      "[40]\ttest-rmse:2.83569\n",
      "[60]\ttest-rmse:2.75949\n",
      "[80]\ttest-rmse:2.72644\n",
      "[100]\ttest-rmse:2.69499\n",
      "[120]\ttest-rmse:2.68441\n",
      "[140]\ttest-rmse:2.68259\n",
      "[160]\ttest-rmse:2.67015\n",
      "[180]\ttest-rmse:2.66512\n",
      "[200]\ttest-rmse:2.66036\n",
      "[220]\ttest-rmse:2.65499\n",
      "[237]\ttest-rmse:2.65717\n",
      "Split #2, This Result: 2.6572, Average Result: 5.1649\n",
      "[13:22:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:56.97348\n",
      "[20]\ttest-rmse:4.30785\n",
      "[29]\ttest-rmse:4.09759\n",
      "Split #3, This Result: 4.0937, Average Result: 4.8971\n",
      "[13:23:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:42.45554\n",
      "[20]\ttest-rmse:3.53778\n",
      "[35]\ttest-rmse:3.57258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 13:23:31,254]\u001b[0m Trial 6 finished with value: 4.63222919575051 and parameters: {'learning_rate': 0.4561469292194776}. Best is trial 0 with value: 4.353045531223534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split #4, This Result: 3.5726, Average Result: 4.6322\n",
      "[13:23:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:57.48723\n",
      "[20]\ttest-rmse:6.68749\n",
      "[40]\ttest-rmse:6.55452\n",
      "[60]\ttest-rmse:6.52345\n",
      "[80]\ttest-rmse:6.50670\n",
      "[100]\ttest-rmse:6.49554\n",
      "[120]\ttest-rmse:6.49313\n",
      "[140]\ttest-rmse:6.48272\n",
      "[160]\ttest-rmse:6.47521\n",
      "[180]\ttest-rmse:6.46924\n",
      "[200]\ttest-rmse:6.46282\n",
      "[220]\ttest-rmse:6.46107\n",
      "[236]\ttest-rmse:6.46190\n",
      "Split #0, This Result: 6.4619, Average Result: 6.4619\n",
      "[13:27:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:51.13640\n",
      "[20]\ttest-rmse:6.70958\n",
      "[40]\ttest-rmse:6.54194\n",
      "[60]\ttest-rmse:6.49020\n",
      "[80]\ttest-rmse:6.44329\n",
      "[100]\ttest-rmse:6.44374\n",
      "[120]\ttest-rmse:6.43420\n",
      "[135]\ttest-rmse:6.43313\n",
      "Split #1, This Result: 6.4311, Average Result: 6.4465\n",
      "[13:29:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:49.83650\n",
      "[20]\ttest-rmse:3.15656\n",
      "[40]\ttest-rmse:2.96462\n",
      "[60]\ttest-rmse:2.90752\n",
      "[80]\ttest-rmse:2.88252\n",
      "[100]\ttest-rmse:2.86877\n",
      "[120]\ttest-rmse:2.84775\n",
      "[140]\ttest-rmse:2.83346\n",
      "[160]\ttest-rmse:2.83103\n",
      "[180]\ttest-rmse:2.83935\n",
      "[185]\ttest-rmse:2.83885\n",
      "Split #2, This Result: 2.8389, Average Result: 5.2440\n",
      "[13:31:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:56.01075\n",
      "[20]\ttest-rmse:4.80253\n",
      "[40]\ttest-rmse:4.48261\n",
      "[60]\ttest-rmse:4.41796\n",
      "[80]\ttest-rmse:4.36570\n",
      "[98]\ttest-rmse:4.38572\n",
      "Split #3, This Result: 4.3853, Average Result: 5.0293\n",
      "[13:33:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:41.72307\n",
      "[20]\ttest-rmse:3.72545\n",
      "[40]\ttest-rmse:3.74208\n",
      "[42]\ttest-rmse:3.73874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 13:33:55,267]\u001b[0m Trial 7 finished with value: 4.771180029615265 and parameters: {'learning_rate': 0.46567067410818896}. Best is trial 0 with value: 4.353045531223534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split #4, This Result: 3.7387, Average Result: 4.7712\n",
      "[13:34:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:41.08541\n",
      "[20]\ttest-rmse:6.49167\n",
      "[40]\ttest-rmse:6.22839\n",
      "[60]\ttest-rmse:6.16133\n",
      "[80]\ttest-rmse:6.12941\n",
      "[100]\ttest-rmse:6.11174\n",
      "[120]\ttest-rmse:6.10162\n",
      "[140]\ttest-rmse:6.08020\n",
      "[154]\ttest-rmse:6.07993\n",
      "Split #0, This Result: 6.0798, Average Result: 6.0798\n",
      "[13:36:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:36.59774\n",
      "[20]\ttest-rmse:7.60951\n",
      "[40]\ttest-rmse:7.49448\n",
      "[60]\ttest-rmse:7.60756\n",
      "[65]\ttest-rmse:7.60523\n",
      "Split #1, This Result: 7.6052, Average Result: 6.8425\n",
      "[13:37:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:35.63607\n",
      "[20]\ttest-rmse:3.16379\n",
      "[40]\ttest-rmse:2.97315\n",
      "[60]\ttest-rmse:2.89816\n",
      "[80]\ttest-rmse:2.85786\n",
      "[100]\ttest-rmse:2.85301\n",
      "[120]\ttest-rmse:2.84235\n",
      "[140]\ttest-rmse:2.83340\n",
      "[160]\ttest-rmse:2.83058\n",
      "[165]\ttest-rmse:2.83128\n",
      "Split #2, This Result: 2.8317, Average Result: 5.5056\n",
      "[13:39:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:39.57632\n",
      "[20]\ttest-rmse:3.74443\n",
      "[40]\ttest-rmse:3.54488\n",
      "[60]\ttest-rmse:3.49007\n",
      "[80]\ttest-rmse:3.46409\n",
      "[100]\ttest-rmse:3.44576\n",
      "[120]\ttest-rmse:3.43648\n",
      "[140]\ttest-rmse:3.43036\n",
      "[160]\ttest-rmse:3.43113\n",
      "[180]\ttest-rmse:3.42294\n",
      "[200]\ttest-rmse:3.42233\n",
      "[211]\ttest-rmse:3.42471\n",
      "Split #3, This Result: 3.4247, Average Result: 4.9854\n",
      "[13:42:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:29.21489\n",
      "[20]\ttest-rmse:3.24843\n",
      "[40]\ttest-rmse:3.18124\n",
      "[60]\ttest-rmse:3.13919\n",
      "[80]\ttest-rmse:3.12923\n",
      "[98]\ttest-rmse:3.13813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 13:44:07,060]\u001b[0m Trial 8 finished with value: 4.615883880852982 and parameters: {'learning_rate': 0.629682447647605}. Best is trial 0 with value: 4.353045531223534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split #4, This Result: 3.1379, Average Result: 4.6159\n",
      "[13:44:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:78.53274\n",
      "[20]\ttest-rmse:6.26211\n",
      "[40]\ttest-rmse:5.78884\n",
      "[60]\ttest-rmse:5.74973\n",
      "[80]\ttest-rmse:5.72783\n",
      "[100]\ttest-rmse:5.70757\n",
      "[120]\ttest-rmse:5.70835\n",
      "[134]\ttest-rmse:5.70567\n",
      "Split #0, This Result: 5.7057, Average Result: 5.7057\n",
      "[13:46:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:69.76681\n",
      "[20]\ttest-rmse:6.45788\n",
      "[40]\ttest-rmse:5.97590\n",
      "[60]\ttest-rmse:5.97755\n",
      "[80]\ttest-rmse:5.94831\n",
      "[100]\ttest-rmse:5.94692\n",
      "[120]\ttest-rmse:5.92901\n",
      "[140]\ttest-rmse:5.92521\n",
      "[160]\ttest-rmse:5.92845\n",
      "[171]\ttest-rmse:5.92562\n",
      "Split #1, This Result: 5.9256, Average Result: 5.8157\n",
      "[13:48:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:67.97273\n",
      "[20]\ttest-rmse:2.98726\n",
      "[40]\ttest-rmse:2.70271\n",
      "[60]\ttest-rmse:2.62934\n",
      "[80]\ttest-rmse:2.56894\n",
      "[100]\ttest-rmse:2.53459\n",
      "[120]\ttest-rmse:2.53021\n",
      "[140]\ttest-rmse:2.51088\n",
      "[160]\ttest-rmse:2.49879\n",
      "[180]\ttest-rmse:2.49063\n",
      "[200]\ttest-rmse:2.48015\n",
      "[220]\ttest-rmse:2.47854\n",
      "[240]\ttest-rmse:2.47439\n",
      "[260]\ttest-rmse:2.47270\n",
      "[280]\ttest-rmse:2.46957\n",
      "[300]\ttest-rmse:2.46582\n",
      "[320]\ttest-rmse:2.46498\n",
      "[340]\ttest-rmse:2.46213\n",
      "[360]\ttest-rmse:2.45843\n",
      "[380]\ttest-rmse:2.45664\n",
      "[400]\ttest-rmse:2.45570\n",
      "[420]\ttest-rmse:2.45411\n",
      "[437]\ttest-rmse:2.45420\n",
      "Split #2, This Result: 2.4541, Average Result: 4.6951\n",
      "[13:54:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:76.98032\n",
      "[20]\ttest-rmse:5.01475\n",
      "[40]\ttest-rmse:4.74237\n",
      "[60]\ttest-rmse:4.55964\n",
      "[80]\ttest-rmse:4.62076\n",
      "[90]\ttest-rmse:4.61680\n",
      "Split #3, This Result: 4.6168, Average Result: 4.6756\n",
      "[13:56:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:57.69034\n",
      "[20]\ttest-rmse:2.78716\n",
      "[37]\ttest-rmse:3.09233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 13:56:44,493]\u001b[0m Trial 9 finished with value: 4.358902504523096 and parameters: {'learning_rate': 0.25924658404049106}. Best is trial 0 with value: 4.353045531223534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split #4, This Result: 3.0923, Average Result: 4.3589\n",
      "[13:56:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:102.28700\n",
      "[20]\ttest-rmse:58.69284\n",
      "[40]\ttest-rmse:34.15188\n",
      "[60]\ttest-rmse:20.33116\n",
      "[80]\ttest-rmse:12.87987\n",
      "[100]\ttest-rmse:9.16770\n",
      "[120]\ttest-rmse:7.50491\n",
      "[140]\ttest-rmse:6.85377\n",
      "[160]\ttest-rmse:6.62807\n",
      "[180]\ttest-rmse:6.54529\n",
      "[200]\ttest-rmse:6.52165\n",
      "[220]\ttest-rmse:6.51245\n",
      "[240]\ttest-rmse:6.48210\n",
      "[260]\ttest-rmse:6.44527\n",
      "[280]\ttest-rmse:6.41788\n",
      "[300]\ttest-rmse:6.41768\n",
      "[304]\ttest-rmse:6.41570\n",
      "Split #0, This Result: 6.4153, Average Result: 6.4153\n",
      "[14:01:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:90.78438\n",
      "[20]\ttest-rmse:52.18874\n",
      "[40]\ttest-rmse:30.72077\n",
      "[60]\ttest-rmse:19.05272\n",
      "[80]\ttest-rmse:12.86491\n",
      "[100]\ttest-rmse:9.71186\n",
      "[120]\ttest-rmse:8.21720\n",
      "[140]\ttest-rmse:7.43376\n",
      "[160]\ttest-rmse:7.04011\n",
      "[180]\ttest-rmse:6.81060\n",
      "[200]\ttest-rmse:6.69164\n",
      "[220]\ttest-rmse:6.59608\n",
      "[240]\ttest-rmse:6.50267\n",
      "[260]\ttest-rmse:6.45782\n",
      "[280]\ttest-rmse:6.39942\n",
      "[300]\ttest-rmse:6.36252\n",
      "[320]\ttest-rmse:6.33871\n",
      "[340]\ttest-rmse:6.31582\n",
      "[360]\ttest-rmse:6.30165\n",
      "[380]\ttest-rmse:6.29280\n",
      "[400]\ttest-rmse:6.28085\n",
      "[420]\ttest-rmse:6.26803\n",
      "[440]\ttest-rmse:6.26199\n",
      "[460]\ttest-rmse:6.25723\n",
      "[480]\ttest-rmse:6.26157\n",
      "[491]\ttest-rmse:6.26262\n",
      "Split #1, This Result: 6.2626, Average Result: 6.3389\n",
      "[14:08:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:88.40743\n",
      "[20]\ttest-rmse:50.84557\n",
      "[40]\ttest-rmse:29.58337\n",
      "[60]\ttest-rmse:17.65409\n",
      "[80]\ttest-rmse:10.85849\n",
      "[100]\ttest-rmse:7.08946\n",
      "[120]\ttest-rmse:5.05001\n",
      "[140]\ttest-rmse:3.95341\n",
      "[160]\ttest-rmse:3.41563\n",
      "[180]\ttest-rmse:3.13542\n",
      "[200]\ttest-rmse:2.98856\n",
      "[220]\ttest-rmse:2.90046\n",
      "[240]\ttest-rmse:2.81656\n",
      "[260]\ttest-rmse:2.76393\n",
      "[280]\ttest-rmse:2.71940\n",
      "[300]\ttest-rmse:2.67786\n",
      "[320]\ttest-rmse:2.65645\n",
      "[340]\ttest-rmse:2.63347\n",
      "[360]\ttest-rmse:2.61807\n",
      "[380]\ttest-rmse:2.60236\n",
      "[400]\ttest-rmse:2.58793\n",
      "[420]\ttest-rmse:2.57627\n",
      "[440]\ttest-rmse:2.56563\n",
      "[460]\ttest-rmse:2.55253\n",
      "[480]\ttest-rmse:2.54663\n",
      "[500]\ttest-rmse:2.53474\n",
      "[520]\ttest-rmse:2.52352\n",
      "[540]\ttest-rmse:2.51362\n",
      "[560]\ttest-rmse:2.50791\n",
      "[580]\ttest-rmse:2.50592\n",
      "[600]\ttest-rmse:2.49949\n",
      "[620]\ttest-rmse:2.48782\n",
      "[640]\ttest-rmse:2.48361\n",
      "[660]\ttest-rmse:2.48127\n",
      "[680]\ttest-rmse:2.47995\n",
      "[700]\ttest-rmse:2.47717\n",
      "[720]\ttest-rmse:2.47485\n",
      "[740]\ttest-rmse:2.47207\n",
      "[760]\ttest-rmse:2.46931\n",
      "[780]\ttest-rmse:2.46703\n",
      "[800]\ttest-rmse:2.46454\n",
      "[820]\ttest-rmse:2.46291\n",
      "[840]\ttest-rmse:2.46219\n",
      "[860]\ttest-rmse:2.46136\n",
      "[880]\ttest-rmse:2.46105\n",
      "[898]\ttest-rmse:2.46272\n",
      "Split #2, This Result: 2.4627, Average Result: 5.0469\n",
      "[14:20:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:100.59551\n",
      "[20]\ttest-rmse:57.23524\n",
      "[40]\ttest-rmse:32.77557\n",
      "[60]\ttest-rmse:18.80968\n",
      "[80]\ttest-rmse:11.02992\n",
      "[100]\ttest-rmse:7.00115\n",
      "[120]\ttest-rmse:5.06618\n",
      "[140]\ttest-rmse:4.24051\n",
      "[160]\ttest-rmse:3.96713\n",
      "[180]\ttest-rmse:3.85935\n",
      "[200]\ttest-rmse:3.78607\n",
      "[220]\ttest-rmse:3.72868\n",
      "[240]\ttest-rmse:3.67953\n",
      "[260]\ttest-rmse:3.65041\n",
      "[280]\ttest-rmse:3.61465\n",
      "[300]\ttest-rmse:3.60350\n",
      "[320]\ttest-rmse:3.57417\n",
      "[340]\ttest-rmse:3.57189\n",
      "[360]\ttest-rmse:3.54816\n",
      "[380]\ttest-rmse:3.51037\n",
      "[400]\ttest-rmse:3.49191\n",
      "[420]\ttest-rmse:3.47118\n",
      "[440]\ttest-rmse:3.46569\n",
      "[460]\ttest-rmse:3.45207\n",
      "[480]\ttest-rmse:3.42850\n",
      "[500]\ttest-rmse:3.41004\n",
      "[520]\ttest-rmse:3.39955\n",
      "[540]\ttest-rmse:3.38789\n",
      "[560]\ttest-rmse:3.37232\n",
      "[580]\ttest-rmse:3.34973\n",
      "[600]\ttest-rmse:3.33848\n",
      "[620]\ttest-rmse:3.32945\n",
      "[640]\ttest-rmse:3.32191\n",
      "[660]\ttest-rmse:3.32028\n",
      "[680]\ttest-rmse:3.31858\n",
      "[700]\ttest-rmse:3.31712\n",
      "[720]\ttest-rmse:3.31572\n",
      "[740]\ttest-rmse:3.31409\n",
      "[760]\ttest-rmse:3.31421\n",
      "[780]\ttest-rmse:3.30986\n",
      "[800]\ttest-rmse:3.30048\n",
      "[820]\ttest-rmse:3.29399\n",
      "[840]\ttest-rmse:3.29228\n",
      "[860]\ttest-rmse:3.29031\n",
      "[880]\ttest-rmse:3.28735\n",
      "[900]\ttest-rmse:3.28121\n",
      "[920]\ttest-rmse:3.27763\n",
      "[940]\ttest-rmse:3.27609\n",
      "[960]\ttest-rmse:3.27187\n",
      "[980]\ttest-rmse:3.27073\n",
      "[1000]\ttest-rmse:3.26938\n",
      "[1020]\ttest-rmse:3.26606\n",
      "[1040]\ttest-rmse:3.26278\n",
      "[1060]\ttest-rmse:3.26217\n",
      "[1080]\ttest-rmse:3.26180\n",
      "[1100]\ttest-rmse:3.26137\n",
      "[1120]\ttest-rmse:3.26095\n",
      "[1140]\ttest-rmse:3.26045\n",
      "[1160]\ttest-rmse:3.26073\n",
      "[1168]\ttest-rmse:3.26063\n",
      "Split #3, This Result: 3.2605, Average Result: 4.6003\n",
      "[14:35:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:75.66782\n",
      "[20]\ttest-rmse:42.51212\n",
      "[40]\ttest-rmse:23.97120\n",
      "[60]\ttest-rmse:13.77861\n",
      "[80]\ttest-rmse:8.31194\n",
      "[100]\ttest-rmse:5.47286\n",
      "[120]\ttest-rmse:4.11862\n",
      "[140]\ttest-rmse:3.48788\n",
      "[160]\ttest-rmse:3.23485\n",
      "[180]\ttest-rmse:3.14655\n",
      "[200]\ttest-rmse:3.13040\n",
      "[215]\ttest-rmse:3.12137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 14:37:52,222]\u001b[0m Trial 10 finished with value: 4.304502234734034 and parameters: {'learning_rate': 0.028326389959607595}. Best is trial 10 with value: 4.304502234734034.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split #4, This Result: 3.1214, Average Result: 4.3045\n",
      "[14:38:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:103.75775\n",
      "[20]\ttest-rmse:78.71982\n",
      "[40]\ttest-rmse:59.95507\n",
      "[60]\ttest-rmse:45.74416\n",
      "[80]\ttest-rmse:35.08567\n",
      "[100]\ttest-rmse:27.08765\n",
      "[120]\ttest-rmse:21.00374\n",
      "[140]\ttest-rmse:16.65107\n",
      "[160]\ttest-rmse:13.43546\n",
      "[180]\ttest-rmse:11.16351\n",
      "[200]\ttest-rmse:9.57466\n",
      "[220]\ttest-rmse:8.47469\n",
      "[240]\ttest-rmse:7.74722\n",
      "[260]\ttest-rmse:7.29557\n",
      "[280]\ttest-rmse:7.00392\n",
      "[300]\ttest-rmse:6.84176\n",
      "[320]\ttest-rmse:6.75688\n",
      "[340]\ttest-rmse:6.67866\n",
      "[360]\ttest-rmse:6.62701\n",
      "[380]\ttest-rmse:6.59599\n",
      "[400]\ttest-rmse:6.58846\n",
      "[420]\ttest-rmse:6.56684\n",
      "[439]\ttest-rmse:6.57371\n",
      "Split #0, This Result: 6.5737, Average Result: 6.5737\n",
      "[14:43:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttest-rmse:92.08527\n",
      "[20]\ttest-rmse:69.95501\n",
      "[40]\ttest-rmse:53.32423\n",
      "[60]\ttest-rmse:40.88957\n",
      "[80]\ttest-rmse:31.58903\n",
      "[100]\ttest-rmse:24.66680\n",
      "[120]\ttest-rmse:19.62034\n",
      "[140]\ttest-rmse:15.92207\n",
      "[160]\ttest-rmse:13.21934\n",
      "[180]\ttest-rmse:11.28312\n",
      "[200]\ttest-rmse:9.90921\n",
      "[220]\ttest-rmse:8.98022\n",
      "[240]\ttest-rmse:8.34126\n",
      "[260]\ttest-rmse:7.87819\n",
      "[280]\ttest-rmse:7.51224\n",
      "[300]\ttest-rmse:7.23981\n",
      "[320]\ttest-rmse:7.04646\n",
      "[340]\ttest-rmse:6.91674\n",
      "[360]\ttest-rmse:6.81394\n",
      "[380]\ttest-rmse:6.72942\n",
      "[400]\ttest-rmse:6.67332\n",
      "[420]\ttest-rmse:6.61951\n",
      "[440]\ttest-rmse:6.57209\n",
      "[460]\ttest-rmse:6.54842\n",
      "[480]\ttest-rmse:6.51349\n",
      "[500]\ttest-rmse:6.47425\n",
      "[520]\ttest-rmse:6.43757\n",
      "[540]\ttest-rmse:6.40623\n",
      "[560]\ttest-rmse:6.37763\n",
      "[580]\ttest-rmse:6.35389\n",
      "[600]\ttest-rmse:6.33371\n",
      "[620]\ttest-rmse:6.31894\n",
      "[640]\ttest-rmse:6.31188\n",
      "[660]\ttest-rmse:6.30187\n",
      "[680]\ttest-rmse:6.29418\n",
      "[700]\ttest-rmse:6.28747\n",
      "[720]\ttest-rmse:6.27869\n",
      "[740]\ttest-rmse:6.27172\n",
      "[760]\ttest-rmse:6.26638\n",
      "[780]\ttest-rmse:6.26053\n",
      "[800]\ttest-rmse:6.25686\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/envSulfurTES/lib/python3.9/site-packages/optuna/study/study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    393\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis feature will be removed in v4.0.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m     )\n\u001b[0;32m--> 400\u001b[0m \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/envSulfurTES/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m show_progress_bar:\n",
      "File \u001b[0;32m~/Projects/envSulfurTES/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/envSulfurTES/lib/python3.9/site-packages/optuna/study/_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    210\u001b[0m     thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m     value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     21\u001b[0m     num_boost_round \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m \u001b[38;5;66;03m# Set this as a maximum, model will stop with early stopping\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: learning_rate, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_boost_round\u001b[39m\u001b[38;5;124m'\u001b[39m: num_boost_round}\n\u001b[0;32m---> 23\u001b[0m     result, addendum \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_train_test_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     25\u001b[0m     scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/envSulfurTES/lib/python3.9/site-packages/stesml-0+unknown-py3.9.egg/stesml/model_tools.py:151\u001b[0m, in \u001b[0;36mbuild_train_test_model\u001b[0;34m(data_dir, model_type, target, metric, scale, parameters, n_repeats, random_state, t_min, t_max)\u001b[0m\n\u001b[1;32m    148\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(model_type, parameters)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Fit the model to training data\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Get predictions for test data\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scale:\n",
      "File \u001b[0;32m~/Projects/envSulfurTES/lib/python3.9/site-packages/stesml-0+unknown-py3.9.egg/stesml/model_tools.py:94\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(model, model_type, X_train, y_train, X_test, y_test, parameters)\u001b[0m\n\u001b[1;32m     90\u001b[0m     dtrain \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(data\u001b[38;5;241m=\u001b[39mX_train,\n\u001b[1;32m     91\u001b[0m                          label\u001b[38;5;241m=\u001b[39my_train)\n\u001b[1;32m     92\u001b[0m     dtest \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(data\u001b[38;5;241m=\u001b[39mX_test,\n\u001b[1;32m     93\u001b[0m                          label\u001b[38;5;241m=\u001b[39my_test)\n\u001b[0;32m---> 94\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# If training ever reaches 10000 rounds without early stopping, this should be increased\u001b[39;49;00m\n\u001b[1;32m     97\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43meval_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    101\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/Projects/envSulfurTES/lib/python3.9/site-packages/xgboost/training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
      "File \u001b[0;32m~/Projects/envSulfurTES/lib/python3.9/site-packages/xgboost/training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/envSulfurTES/lib/python3.9/site-packages/xgboost/core.py:1680\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1680\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd2871",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72d36831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layers': 2, 'n_hidden_units': 79, 'batch_size': 339, 'epochs': 7}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cf2e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_value = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0223de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0137617092656621"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd901f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
